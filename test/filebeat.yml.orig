###################### Filebeat-ING Configuration file for GFME-Gateay #########################


#=========================== Filebeat prospectors =============================
filebeat.inputs:

  # Each - is a prospector. Most options can be set at the prospector level, so
  # you can use different prospectors for various configurations.
  # Below are the prospector specific configurations.

  - type: log

    # Change to true to enable this prospector configuration.
    enabled: true

    # Paths that should be crawled and fetched. Glob based paths.
    paths:
      #- /var/log/*.log
      - /app/mountedlogs/*.log
      #- c:\programdata\elasticsearch\logs\*

    #document_type: apache-access

    # Exclude lines. A list of regular expressions to match. It drops the lines that are
    # matching any regular expression from the list.
    #exclude_lines: ['^DBG']
    #exclude_lines: ['healthcheck']

    # Include lines. A list of regular expressions to match. It exports the lines that are
    # matching any regular expression from the list.
    #include_lines: ['^ERR', '^WARN']

    # Exclude files. A list of regular expressions to match. Filebeat drops the files that
    # are matching any regular expression from the list. By default, no files are dropped.
    #exclude_files: ['.gz$']

    # Optional additional fields. These fields can be freely picked
    # to add additional information to the crawled log files for filtering
    fields_under_root: true
    fields:
      component: gfme-gateway
      environment: test
    #  review: 1

    ### Multiline options

    # Mutiline can be used for log messages spanning multiple lines. This is common
    # for Java Stack Traces or C-Line Continuation

    # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [
    #multiline.pattern: ^\[

    # Defines if the pattern set under pattern should be negated or not. Default is false.
    #multiline.negate: false

    # Match can be set to "after" or "before". It is used to define if lines should be append to a pattern
    # that was (not) matched before or after or as long as a pattern is not matched based on negate.
    # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash
    #multiline.match: after

  #================================ General =====================================

  # The name of the shipper that publishes the network data. It can be used to group
  # all the transactions sent by a single shipper in the web interface.
  #name:

  # The tags of the shipper are included in their own field with each
  # transaction published.
    tags: ["Filebeat-ING gfme-gateway"]

  #================================ Processors =====================================

  # Configure processors to enhance or manipulate events generated by the beat.

# input example for the grok: 2019-02-08T11:41:24.788+0100    INFO    [testmonitoring]        log/log.go:144  This is an info message

processors:
  - grok:
      patterns: ["\\[%{HTTPDATE:timestamp}\\] - %{IPORHOST:attributes.remote_addr} - \\[%{NOTSPACE:attributes.client_app} @ %{NOTSPACE:attributes.client_env}\\] - %{NOTSPACE:attributes.has_irm_group} - %{QUOTEDSTRING:attributes.request} %{NUMBER:errorCode:int} %{NUMBER:body_bytes_sent:float} %{QUOTEDSTRING:attributes.http_referer} %{QUOTEDSTRING:http_user_agent} %{NUMBER:upstream_response_time:float} %{GREEDYDATA:attributes.http_x_forwarded_for}"]
      timestamps: ["2/Jan/2006:15:04:05 -0700"]
  - javascript:
      file: "/app/application/filebeat.js"


  #================================ Outputs =====================================

  # Configure what output to use when sending the data collected by the beat.

output.kafka:
  enabled: true
  topic: 'log_hermes_tech_topic'
  codec.avro:
    file: "/app/configuration/filebeat.avsc"
  partition.round_robin:
  reachable_only: false
  required_acks: 1
  #version : 0.11
  compression: "none"
  compression_level: 0
  keep_alive: 3
  channel_buffer_size: 1
  max_message_bytes: 1000000
  keepfiles: 7

  hosts: ["kafka-tst-0.europe.intranet:9092","kafka-tst-1.europe.intranet:9092"]
  # ----------
  # SSL config
  # ----------
  ssl.enabled: false
  #ssl.certificate_authorities: "/usr/local/ssl/clrv0000112237.ic.ing.net.cer"
  #ssl.certificate : "/usr/local/ssl/clrv0000112237.ic.ing.net.cer"
  #ssl.key : "/usr/local/ssl/clrv0000112237.ic.ing.net.key"
  #ssl.key_passphrase : "passphrase"

  #ssl.certificate_authorities: ["/opt/cdp/key/rootg3_b64.cer","/opt/cdp/key/intg3_b64.cer","/opt/cdp/key/pubg3_b64.cer"]

  output.console:
    pretty: true

  #================================ Logging =====================================
  # Sets log level. The default log level is info.
  # Available log levels are: error, warning, info, debug
logging.level: info
logging.to_stderr: true
logging.to_files: true
logging.files:
  path: /app/log
  name: filebeat
  interval: 24h
  keepfiles: 10
  permissions: 0644
  # At debug level, you can selectively enable logging only for some components.
  # To enable all selectors use ["*"]. Examples of other selectors are "beat",
  # "publish", "service".
#logging.selectors: ["*"]